# IrisData
## Пример данных Iris На Python Numpy

Набор данных Iris содержит более 150 записей элементов. У каждого элемента есть четыре числовые переменные-предиктора (часто называемые признаками): длина и ширина чашелистика, длина и ширина лепестка, за которыми следует вид ("сетоза", "разноцветный" или "виргиния").

- Демонстрационная программа использует кодировку меток 1 из N, поэтому setosa = (1,0,0), versicolor = (0,1,0) и virginica = (0,0,1). Цель состоит в том, чтобы предсказать виды по длине и ширине чашелистика и лепестка.

- Набор данных из 150 элементов содержит 50 элементов setosa, за которыми следуют 50 versicolor, а затем 50 virginica. Перед написанием демонстрационной программы имеется файл обучающих данных из 120 элементов (с использованием первых 30 для каждого вида) и файл тестовых данных из 30 элементов (оставшиеся 10 для каждого вида).

- Демонстрационная программа создает простую нейронную сеть с четырьмя входными узлами (по одному для каждого объекта), пятью скрытыми узлами обработки (количество скрытых узлов является свободным параметром и должно определяться методом проб и ошибок) и тремя выходными узлами (соответствующими закодированным видам). Демонстрационная версия загрузила обучающие и тестовые данные в две матрицы.

- Алгоритм обратного распространения является итеративным, и вы должны указать максимальное количество итераций (50 в демонстрации) и скорость обучения (0,050), которая определяет, насколько изменяется каждое значение веса и смещения на каждой итерации. Небольшие значения скорости обучения приводят к медленному, но устойчивому обучению. Большие скорости обучения приводят к более быстрому обучению с риском превышения значений хорошего веса и смещения. Максимальная итерация и скорость наклона являются свободными параметрами.

- Демонстрационная версия отображает значение среднеквадратичной ошибки каждые 10 итераций во время обучения. Как вы вскоре увидите, существует два типа ошибок, которые обычно используются при обратном распространении, и выбор типа ошибки влияет на реализацию обратного распространения. После завершения обучения демонстрационная версия рассчитала точность классификации результирующей модели на основе обучающих данных (0,9333 = 112 из 120 правильных) и тестовых данных (0,9667 = 29 из 30 правильных). Точность классификации набора тестовых данных - это очень грубое приближение к точности, которую вы ожидаете увидеть для новых, ранее невидимых данных.